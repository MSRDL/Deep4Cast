{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Distributed Dataset\n",
    "\n",
    "This notebook is designed to give a simple introduction to forecasting using the Deep4Cast package. The time series data is taken from the [M4 dataset](https://github.com/M4Competition/M4-methods/tree/master/Dataset), specifically, the ``Daily`` subset of the data. \n",
    "\n",
    "Since most of the content is duplicated from the M4 Daily notebook we will here focus only on how to use the distributed dataset features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T17:23:44.499193Z",
     "start_time": "2019-08-01T17:23:43.686001Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from deep4cast.forecasters import Forecaster\n",
    "from deep4cast.models import WaveNet\n",
    "from deep4cast.datasets import TimeSeriesDataset\n",
    "import deep4cast.transforms as transforms\n",
    "import deep4cast.metrics as metrics\n",
    "\n",
    "# Make RNG predictable\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "# Use a gpu if available, otherwise use cpu\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "In this section we prepare the dataset, write it into parquet files, and prepare it for easy consumption with PyTorch-based data loaders. Model construction and training will be done in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T17:23:44.507062Z",
     "start_time": "2019-08-01T17:23:44.501105Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('data/Daily-train.csv'):\n",
    "    !wget https://raw.githubusercontent.com/M4Competition/M4-methods/master/Dataset/Train/Daily-train.csv -P data/\n",
    "if not os.path.exists('data/Daily-test.csv'):\n",
    "    !wget https://raw.githubusercontent.com/M4Competition/M4-methods/master/Dataset/Test/Daily-test.csv -P data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T17:24:00.652072Z",
     "start_time": "2019-08-01T17:23:44.509155Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V9911</th>\n",
       "      <th>V9912</th>\n",
       "      <th>V9913</th>\n",
       "      <th>V9914</th>\n",
       "      <th>V9915</th>\n",
       "      <th>V9916</th>\n",
       "      <th>V9917</th>\n",
       "      <th>V9918</th>\n",
       "      <th>V9919</th>\n",
       "      <th>V9920</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D1</td>\n",
       "      <td>1017.10</td>\n",
       "      <td>1019.30</td>\n",
       "      <td>1017.00</td>\n",
       "      <td>1019.20</td>\n",
       "      <td>1018.70</td>\n",
       "      <td>1015.60</td>\n",
       "      <td>1018.50</td>\n",
       "      <td>1018.30</td>\n",
       "      <td>1018.4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D2</td>\n",
       "      <td>2793.70</td>\n",
       "      <td>2793.80</td>\n",
       "      <td>2803.70</td>\n",
       "      <td>2805.80</td>\n",
       "      <td>2802.30</td>\n",
       "      <td>2795.00</td>\n",
       "      <td>2806.40</td>\n",
       "      <td>2782.20</td>\n",
       "      <td>2780.3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D3</td>\n",
       "      <td>1091.30</td>\n",
       "      <td>1088.50</td>\n",
       "      <td>1085.70</td>\n",
       "      <td>1082.90</td>\n",
       "      <td>1080.10</td>\n",
       "      <td>1077.30</td>\n",
       "      <td>1074.50</td>\n",
       "      <td>1071.70</td>\n",
       "      <td>1068.9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D4</td>\n",
       "      <td>1092.00</td>\n",
       "      <td>1078.00</td>\n",
       "      <td>1064.00</td>\n",
       "      <td>1050.00</td>\n",
       "      <td>1036.00</td>\n",
       "      <td>1022.00</td>\n",
       "      <td>1008.00</td>\n",
       "      <td>1092.00</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D5</td>\n",
       "      <td>2938.63</td>\n",
       "      <td>2956.44</td>\n",
       "      <td>2964.41</td>\n",
       "      <td>2972.41</td>\n",
       "      <td>3014.97</td>\n",
       "      <td>3014.23</td>\n",
       "      <td>3024.08</td>\n",
       "      <td>3031.97</td>\n",
       "      <td>3062.7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 9920 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   V1       V2       V3       V4       V5       V6       V7       V8       V9  \\\n",
       "0  D1  1017.10  1019.30  1017.00  1019.20  1018.70  1015.60  1018.50  1018.30   \n",
       "1  D2  2793.70  2793.80  2803.70  2805.80  2802.30  2795.00  2806.40  2782.20   \n",
       "2  D3  1091.30  1088.50  1085.70  1082.90  1080.10  1077.30  1074.50  1071.70   \n",
       "3  D4  1092.00  1078.00  1064.00  1050.00  1036.00  1022.00  1008.00  1092.00   \n",
       "4  D5  2938.63  2956.44  2964.41  2972.41  3014.97  3014.23  3024.08  3031.97   \n",
       "\n",
       "      V10  ...  V9911  V9912  V9913  V9914  V9915  V9916  V9917  V9918  V9919  \\\n",
       "0  1018.4  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1  2780.3  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "2  1068.9  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3  1078.0  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "4  3062.7  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "   V9920  \n",
       "0    NaN  \n",
       "1    NaN  \n",
       "2    NaN  \n",
       "3    NaN  \n",
       "4    NaN  \n",
       "\n",
       "[5 rows x 9920 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/Daily-train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transform from wide to long format to facilitate paritioning parquet files on the time series id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T17:24:04.016429Z",
     "start_time": "2019-08-01T17:24:00.653918Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D1</td>\n",
       "      <td>1017.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D2</td>\n",
       "      <td>2793.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D3</td>\n",
       "      <td>1091.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D4</td>\n",
       "      <td>1092.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D5</td>\n",
       "      <td>2938.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   V1    value\n",
       "0  D1  1017.10\n",
       "1  D2  2793.70\n",
       "2  D3  1091.30\n",
       "3  D4  1092.00\n",
       "4  D5  2938.63"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.melt(id_vars='V1')\n",
    "df = df[df.value.notnull()]\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.drop('variable', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create parquet files by paritioning on the time series id. This creates directories with parquet files containing the entirety of the single time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T17:24:16.690077Z",
     "start_time": "2019-08-01T17:24:04.018107Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_parquet(\n",
    "    'data/m4/daily/',\n",
    "    engine='fastparquet',\n",
    "    partition_cols=['V1'],\n",
    "    compression=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data handling\n",
    "\n",
    "We use the DataLoader object from PyTorch to build batches from the data set.\n",
    "\n",
    "However, we first need to specify how much history to use in creating a forecast of a given length:\n",
    "- horizon = time steps to forecast\n",
    "- lookback = time steps leading up to the period to be forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T17:24:16.695828Z",
     "start_time": "2019-08-01T17:24:16.692204Z"
    }
   },
   "outputs": [],
   "source": [
    "horizon = 14\n",
    "lookback = 128\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.LogTransform(targets=[0], offset=1.0),\n",
    "    transforms.RemoveLast(targets=[0]),\n",
    "    transforms.Target(targets=[0]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T17:24:17.320766Z",
     "start_time": "2019-08-01T17:24:16.697613Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>D1</th>\n",
       "      <td>1006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D10</th>\n",
       "      <td>674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D100</th>\n",
       "      <td>1006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1000</th>\n",
       "      <td>1052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D1001</th>\n",
       "      <td>1052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       value\n",
       "V1          \n",
       "D1      1006\n",
       "D10      674\n",
       "D100    1006\n",
       "D1000   1052\n",
       "D1001   1052"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfg = df.groupby('V1').count()\n",
    "dfg.to_csv('data/m4/daily/_metadata_partition.csv', header=None)\n",
    "dfg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TimeSeriesDataset` inherits from [Torch Datasets](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) for use with [Torch DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader). It handles the creation of the examples used to train the network using `lookback` and `horizon` to partition the time series.\n",
    "\n",
    "Instead of providing an array of ``numpy`` time series, we here provide a path to the paritioned parquet files as well as a list of files locations containing metadata on the time series ids. The metadata file has the partition name (first column) and the length of the time series (second column). This will be used to calculate the number of examples in each time series.\n",
    "\n",
    "Finally, since the entire time series is stored in the parquet file, if we want to perform a train-test split then we set ``split='train'``, this holds out the final horizon from each time series from training. Setting ``split='test'`` will conversely provide only the final ``lookback`` and ``horizon``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T17:24:20.372816Z",
     "start_time": "2019-08-01T17:24:17.322796Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train = TimeSeriesDataset(\n",
    "    path_parquet='data/m4/daily/',\n",
    "    path_metadata=['data/m4/daily/_metadata_partition.csv'],\n",
    "    lookback=lookback, \n",
    "    horizon=horizon,\n",
    "    step=1,\n",
    "    transform=transform,\n",
    "    thinning=0.1,\n",
    "    split='train'\n",
    ")\n",
    "dataloader_train = DataLoader(\n",
    "    data_train, \n",
    "    batch_size=512, \n",
    "    shuffle=True, \n",
    "    pin_memory=True,\n",
    "    num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T17:24:20.384823Z",
     "start_time": "2019-08-01T17:24:20.374533Z"
    }
   },
   "outputs": [],
   "source": [
    "model = WaveNet(input_channels=1,\n",
    "                output_channels=1,\n",
    "                horizon=horizon, \n",
    "                n_layers=7)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "loss = torch.distributions.StudentT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T17:28:15.037658Z",
     "start_time": "2019-08-01T17:24:20.386316Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/austin/miniconda3/envs/d4c/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 [931419/931419 (100%)]\tLoss: -1.971866\tElapsed/Remaining: 3m52s/0m0s   "
     ]
    }
   ],
   "source": [
    "forecaster = Forecaster(model, loss, optim, n_epochs=1, device=device)\n",
    "forecaster.fit(dataloader_train, eval_model=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "We need to append the ``lookback`` to the test data so that we can make forecasts to compare to actuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T17:28:31.507650Z",
     "start_time": "2019-08-01T17:28:15.039723Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('data/Daily-train.csv')\n",
    "data_test = pd.read_csv('data/Daily-test.csv')\n",
    "data_train = data_train.iloc[:, 1:].values\n",
    "data_test = data_test.iloc[:, 1:].values\n",
    "\n",
    "data_arr = []\n",
    "for ts_train, ts_test in zip(data_train, data_test):\n",
    "    ts_a = ts_train[~np.isnan(ts_train)]\n",
    "    ts_b = ts_test\n",
    "    ts = np.concatenate([ts_a, ts_b])[None, :]\n",
    "    data_arr.append(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we provide a list of ``numpy`` arrays containing the train and test time series. ``TimeSeriesDataset`` creates a test split (``split='test'``) providing the final ``lookback`` and ``horizon`` of each time series so that the ``lookback`` can be used to create a forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T17:28:31.517061Z",
     "start_time": "2019-08-01T17:28:31.509487Z"
    }
   },
   "outputs": [],
   "source": [
    "data_test = TimeSeriesDataset(\n",
    "    time_series=data_arr,\n",
    "    lookback=lookback, \n",
    "    horizon=horizon, \n",
    "    step=1,\n",
    "    transform=transform,\n",
    "    split='test'\n",
    ")\n",
    "dataloader_test = DataLoader(\n",
    "    data_test, \n",
    "    batch_size=1024, \n",
    "    shuffle=False,\n",
    "    num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T17:28:51.065291Z",
     "start_time": "2019-08-01T17:28:31.518886Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test = []\n",
    "for example in dataloader_test:\n",
    "    example = dataloader_test.dataset.transform.untransform(example)\n",
    "    y_test.append(example['y'])\n",
    "y_test = np.concatenate(y_test)\n",
    "\n",
    "y_samples = forecaster.predict(dataloader_test, n_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-01T17:28:51.166945Z",
     "start_time": "2019-08-01T17:28:51.067609Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAPE: 3.007478952407837%\n"
     ]
    }
   ],
   "source": [
    "test_smape = metrics.smape(y_samples, y_test)\n",
    "\n",
    "print('SMAPE: {}%'.format(test_smape.mean()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d4c",
   "language": "python",
   "name": "d4c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
